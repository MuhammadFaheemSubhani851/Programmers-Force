{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame({'Color': ['Red', 'Green','Blue','Red','Green','Black']})\n",
        "Encoded_data  =pd.get_dummies(data['Color'])\n",
        "result  = pd.concat([data, Encoded_data], axis =1)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIeZwqtSasfU",
        "outputId": "ec4daf6c-ccd4-4343-cf15-89c07faeb24a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color  Black  Blue  Green  Red\n",
            "0    Red      0     0      0    1\n",
            "1  Green      0     0      1    0\n",
            "2   Blue      0     1      0    0\n",
            "3    Red      0     0      0    1\n",
            "4  Green      0     0      1    0\n",
            "5  Black      1     0      0    0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKqY6bCrbXdv",
        "outputId": "f2317f88-aa2e-4fea-e3f1-5d35c83823d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Example text data (three sentences as documents)\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"She sells sea shells by the sea shore.\",\n",
        "    \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\"\n",
        "]\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "# Fit and transform the documents into the BoW representation\n",
        "bow_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "bow_array = bow_matrix.toarray()\n",
        "features = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "print(\"BoW Matrix:\")\n",
        "print(bow_matrix)\n",
        "\n",
        "# Print the BoW array (NumPy array version)\n",
        "print(\"\\nBoW Array:\")\n",
        "print(bow_array)\n",
        "\n",
        "# Print the feature names\n",
        "print(\"\\nFeatures (Words or N-grams):\")\n",
        "print(features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd-00AVFplzY",
        "outputId": "6838d77d-0d08-4259-d430-e78cb62cc179"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Matrix:\n",
            "  (0, 18)\t2\n",
            "  (0, 12)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 8)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 9)\t1\n",
            "  (0, 4)\t1\n",
            "  (1, 18)\t1\n",
            "  (1, 15)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 13)\t2\n",
            "  (1, 16)\t1\n",
            "  (1, 1)\t1\n",
            "  (1, 17)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 10)\t1\n",
            "  (2, 19)\t2\n",
            "  (2, 21)\t1\n",
            "  (2, 20)\t2\n",
            "  (2, 2)\t2\n",
            "  (2, 7)\t1\n",
            "  (2, 3)\t1\n",
            "\n",
            "BoW Array:\n",
            "[[1 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 2 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 0 0 0]\n",
            " [0 0 2 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 2 2 1]]\n",
            "\n",
            "Features (Words or N-grams):\n",
            "['brown' 'by' 'chuck' 'could' 'dog' 'fox' 'how' 'if' 'jumps' 'lazy' 'much'\n",
            " 'over' 'quick' 'sea' 'sells' 'she' 'shells' 'shore' 'the' 'wood'\n",
            " 'woodchuck' 'would']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bit advanced code on OneHotEncoder**"
      ],
      "metadata": {
        "id": "pARR9bqGwnTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Sample data with a categorical feature\n",
        "data = {\n",
        "    'City': ['New York', 'San Francisco', 'Los Angeles', 'Chicago', 'San Francisco', 'New York']\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create an instance of the OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "# Perform one-hot encoding on the 'City' column\n",
        "one_hot_encoded = encoder.fit_transform(df[['City']])\n",
        "\n",
        "one_hot_array = one_hot_encoded.toarray()\n",
        "\n",
        "# Get the feature names (unique categories in the 'City' column)\n",
        "feature_names = encoder.get_feature_names_out(input_features=['City'])\n",
        "\n",
        "# Create a new DataFrame with the one-hot encoded features\n",
        "one_hot_df = pd.DataFrame(one_hot_array, columns=feature_names)\n",
        "\n",
        "# Concatenate the one-hot DataFrame with the original DataFrame to see the results\n",
        "result_df = pd.concat([df, one_hot_df], axis=1)\n",
        "\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9XWxoAepxFO",
        "outputId": "e302904e-e73e-45fa-dd61-ad7dbc160dc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            City  City_Chicago  City_Los Angeles  City_New York  \\\n",
            "0       New York           0.0               0.0            1.0   \n",
            "1  San Francisco           0.0               0.0            0.0   \n",
            "2    Los Angeles           0.0               1.0            0.0   \n",
            "3        Chicago           1.0               0.0            0.0   \n",
            "4  San Francisco           0.0               0.0            0.0   \n",
            "5       New York           0.0               0.0            1.0   \n",
            "\n",
            "   City_San Francisco  \n",
            "0                 0.0  \n",
            "1                 1.0  \n",
            "2                 0.0  \n",
            "3                 0.0  \n",
            "4                 1.0  \n",
            "5                 0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bit advance code on BOW**"
      ],
      "metadata": {
        "id": "1xNyBx0Sw4cI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample data with text documents\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"She sells sea shells by the sea shore.\",\n",
        "    \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\"\n",
        "]\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "bow_matrix = vectorizer.fit_transform(documents)\n",
        "bow_array = bow_matrix.toarray()\n",
        "features = vectorizer.get_feature_names_out()\n",
        "bow_df = pd.DataFrame(bow_array, columns=features)\n",
        "\n",
        "print(\"Bag-of-Words Matrix:\")\n",
        "print(bow_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "776VjlGzwzqV",
        "outputId": "09befcab-e633-4f8f-9472-4f42eb86e11f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-Words Matrix:\n",
            "   brown  by  chuck  could  dog  fox  how  if  jumps  lazy  ...  quick  sea  \\\n",
            "0      1   0      0      0    1    1    0   0      1     1  ...      1    0   \n",
            "1      0   1      0      0    0    0    0   0      0     0  ...      0    2   \n",
            "2      0   0      2      1    0    0    1   1      0     0  ...      0    0   \n",
            "\n",
            "   sells  she  shells  shore  the  wood  woodchuck  would  \n",
            "0      0    0       0      0    2     0          0      0  \n",
            "1      1    1       1      1    1     0          0      0  \n",
            "2      0    0       0      0    0     2          2      1  \n",
            "\n",
            "[3 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BydK_yMvxF-4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}