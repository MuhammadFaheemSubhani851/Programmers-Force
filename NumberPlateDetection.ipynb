{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "4TO12JzgS1QM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtrWl-1TGqjC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Flatten , Dense\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the dataset**"
      ],
      "metadata": {
        "id": "En15XHd9S6ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Training Dataset\n",
        "train_dataset_path = \"train_labels.csv\"\n",
        "train_dataset = pd.read_csv(train_dataset_path)\n",
        "\n",
        "# Display the Data of the Dataset\n",
        "train_dataset.head()"
      ],
      "metadata": {
        "id": "fbFZdefaIG0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "evQJLlKiKdEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the List for Images and Targets\n",
        "train_images  = []\n",
        "train_labels = []\n",
        "\n",
        "# Define the Path of the Images\n",
        "base_path_images = \"/content/drive/MyDrive/Cars\"\n",
        "\n",
        "count = 0\n",
        "# Extract the Images by Iterating\n",
        "for filename in train_dataset[\"filename\"]:\n",
        "    # Extract the Image Path\n",
        "    image_path = os.path.join(base_path_images, filename)\n",
        "\n",
        "    # Read the Image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Extract the Image Width and Height\n",
        "    w , h = image.size\n",
        "\n",
        "    # Get the X,Y,Widt,Height\n",
        "    x = float(train_dataset[\"xmin\"][count]) / w\n",
        "    y = float(train_dataset[\"ymin\"][count]) / h\n",
        "    width  = float(train_dataset[\"xmax\"][count]) / w\n",
        "    height = float(train_dataset[\"ymax\"][count]) / h\n",
        "\n",
        "\n",
        "    # Reshape the Image\n",
        "    reshape_image = image.resize((224,224))\n",
        "\n",
        "    # Append the Images and Targets\n",
        "    train_images.append(np.array(reshape_image))\n",
        "    train_labels.append((x,y,width,height))\n",
        "\n",
        "    count += 1\n"
      ],
      "metadata": {
        "id": "vWPhKYmDKHlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shape of train images and labels**"
      ],
      "metadata": {
        "id": "TmTONUuHSuEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of the Images is : {np.shape(train_images)}\")\n",
        "print(f\"Shape of the Target is : {np.shape(train_labels)}\")"
      ],
      "metadata": {
        "id": "cp9Re3QpKqab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the images and targets in the Numpy Matrix\n",
        "Images = np.array(train_images , dtype = \"float32\") / 255.0\n",
        "Targets = np.array(train_labels , dtype = \"float32\")"
      ],
      "metadata": {
        "id": "xB9k9nVntdhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply Train-Test Split**"
      ],
      "metadata": {
        "id": "-vvgD1A8TCqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(Images, Targets, test_size=0.1, random_state=42)\n",
        "\n",
        "# Display the Shapes\n",
        "print(f\"Shape of x_train is: {x_train.shape}\")\n",
        "print(f\"Shape of y_train is: {y_train.shape}\")\n",
        "print(f\"Shape of x_val is: {x_val.shape}\")\n",
        "print(f\"Shape of y_val is: {y_val.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf_kqzNhTGIo",
        "outputId": "df878e6d-2582-46d5-dcb9-0cfe5a4f9043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train is: (202, 224, 224, 3)\n",
            "Shape of y_train is: (202, 4)\n",
            "Shape of x_val is: (23, 224, 224, 3)\n",
            "Shape of y_val is: (23, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading pre_trained Model**"
      ],
      "metadata": {
        "id": "1yr5mXTHTrNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelVGG16 = VGG16(weights = \"imagenet\" , include_top = False , input_shape = (224,224,3))\n",
        "\n",
        "# Display the Summary of the VGG16 Model\n",
        "modelVGG16.summary()"
      ],
      "metadata": {
        "id": "gr4YDbKvTunE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding Layers according to need**"
      ],
      "metadata": {
        "id": "zgsKK07wWt7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the Trainable Layers of VGG16\n",
        "modelVGG16.trainable = False\n",
        "\n",
        "# Now Flatten The VGG16 Model Outpust\n",
        "flatten = Flatten()(modelVGG16.output)\n",
        "\n",
        "# Now Applying the Fully Connected Layers\n",
        "x = Dense(256 , activation = \"relu\")(flatten)\n",
        "x = Dense(128 , activation = \"relu\")(x)\n",
        "x = Dense(64  , activation = \"relu\")(x)\n",
        "x = Dense(32  , activation = \"relu\")(x)\n",
        "x = Dense(16 , activation = \"relu\")(x)\n",
        "bbox = Dense(4)(x)\n",
        "\n",
        "# Create the FinalModels\n",
        "finalModel = Model(inputs = modelVGG16.input , outputs = bbox)\n",
        "\n",
        "# Now Display the Summary of the Final Model\n",
        "finalModel.summary()"
      ],
      "metadata": {
        "id": "-PJNRswpVi0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "finalModel.compile(optimizer='adam', loss='mse')\n"
      ],
      "metadata": {
        "id": "Cv_YuoQwWJLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**describing no. of epochs**"
      ],
      "metadata": {
        "id": "41qSMNFbW0ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with integer-encoded labels\n",
        "history = finalModel.fit(x_train , y_train , validation_data = (x_val , y_val) , epochs = 500 , batch_size = 32, verbose = 1)"
      ],
      "metadata": {
        "id": "yJBewAvRWkwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict model on testing dataset**"
      ],
      "metadata": {
        "id": "fHGrcKXjbgSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_path = \"test_labels.csv\"\n",
        "\n",
        "# Read the Test CSV File\n",
        "test_dataset = pd.read_csv(test_dataset_path)"
      ],
      "metadata": {
        "id": "n5bxlx0MW5LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now get the Images\n",
        "for filename in test_dataset[\"filename\"]:\n",
        "    # Get the Image Path\n",
        "    image_path = os.path.join(base_path_images, filename)\n",
        "\n",
        "    # Read the Image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Extract the Size of Image\n",
        "    w,h = image.size\n",
        "\n",
        "    # Resize the Image\n",
        "    resize_image = image.resize((224,224))\n",
        "\n",
        "    # Convert the Numpy Array Image\n",
        "    cv2_image = np.array(resize_image)\n",
        "\n",
        "    # Rescale the Image\n",
        "    cv2_image = cv2_image / 255.0\n",
        "\n",
        "    # Predict the Image\n",
        "    finalImage = np.expand_dims(cv2_image,axis=0)\n",
        "    prediction = finalModel.predict(finalImage)[0]\n",
        "\n",
        "    # Now get the X,Y,Width and Height\n",
        "    x = int(prediction[0] * w)\n",
        "    y = int(prediction[1] * h)\n",
        "    width = int(prediction[2] * w)\n",
        "    height = int(prediction[3] * h)\n",
        "\n",
        "    print(x,y,width,height)\n",
        "\n",
        "\n",
        "    # Again Create Numpy Array\n",
        "    cv2_image_2 = np.array(image)\n",
        "    cv2.rectangle(cv2_image_2 , (x,y) , (width , height) , (255,0,0) , 2)\n",
        "\n",
        "    # Display the Image\n",
        "    display(image)\n",
        "    display(Image.fromarray(cv2_image_2))"
      ],
      "metadata": {
        "id": "LUfarAWrZKqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Define a directory to save the cropped images\n",
        "output_dir = \"/content/drive/MyDrive/Car/Cropped_Images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "count = 0\n",
        "\n",
        "# Now get the Images\n",
        "for filename in test_dataset[\"filename\"]:\n",
        "    # Get the Image Path\n",
        "    image_path = os.path.join(base_path_images, filename)\n",
        "    # Read the Image\n",
        "    image = Image.open(image_path)\n",
        "    # Extract the Size of Image\n",
        "    w, h = image.size\n",
        "    # Resize the Image\n",
        "    resize_image = image.resize((224, 224))\n",
        "    # Convert the Numpy Array Image\n",
        "    cv2_image = np.array(resize_image)\n",
        "    # Rescale the Image\n",
        "    cv2_image = cv2_image / 255.0\n",
        "    # Predict the Image\n",
        "    finalImage = np.expand_dims(cv2_image, axis=0)\n",
        "    prediction = finalModel.predict(finalImage)[0]\n",
        "    # Now get the X, Y, Width and Height\n",
        "    x = int(prediction[0] * w)\n",
        "    y = int(prediction[1] * h)\n",
        "    width = int(prediction[2] * w)\n",
        "    height = int(prediction[3] * h)\n",
        "\n",
        "    # Ensure the coordinates are within the image bounds\n",
        "    x = max(0, x)\n",
        "    y = max(0, y)\n",
        "    width = min(width, w - x)\n",
        "    height = min(height, h - y)\n",
        "\n",
        "    # Again Create Numpy Array\n",
        "    cv2_image_2 = np.array(image)\n",
        "    cv2.rectangle(cv2_image_2, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
        "\n",
        "    # Crop the region defined by the bounding box if it is within bounds\n",
        "    if width > 0 and height > 0:\n",
        "        cropped_image = cv2_image_2[y:y + height, x:x + width]\n",
        "\n",
        "        # Save the cropped image\n",
        "        cropped_image_path = os.path.join(output_dir, f\"cropped_{filename}\")\n",
        "        cv2.imwrite(\"/content/drive/MyDrive/Car/Cropped_Images/Image{}.jpg\".format(count), cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR))\n",
        "        count += 1\n",
        "\n",
        "        # Display the Image\n",
        "        display(image)\n",
        "        display(Image.fromarray(cv2_image_2))\n",
        "        display(Image.fromarray(cropped_image))\n",
        "    else:\n",
        "        print(f\"Skipping {filename} as the bounding box is out of bounds.\")\n"
      ],
      "metadata": {
        "id": "GulPZLpa7o6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "0C8mShLub_Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# Define the directory containing the cropped images\n",
        "cropped_images_dir = \"/content/drive/MyDrive/Car/Cropped_Images\"\n",
        "\n",
        "# Function to apply OCR on the cropped images\n",
        "def apply_ocr_on_images():\n",
        "    for filename in os.listdir(cropped_images_dir):\n",
        "        if filename.startswith(\"cropped_\"):\n",
        "            image_path = os.path.join(cropped_images_dir, filename)\n",
        "            image = Image.open(image_path)\n",
        "            text = pytesseract.image_to_string(image, lang='eng')\n",
        "            print(f\"Image: {filename}, Extracted Text: {text}\")\n",
        "\n",
        "# Call the function to apply OCR on the cropped images\n",
        "apply_ocr_on_images()\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "jl-XEdkohUxu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}